#!/bin/bash

cd "$(dirname "$0")"

fetch_data() {
    URL="$1"
    DIR="$2"
    mkdir -p $DIR downloads
    if [ ! -f "downloads/$DIR.zip" ]; then # if file has been downloaded before
        wget $URL -O "downloads/$DIR.zip"
    fi
    unzip "downloads/$DIR.zip" -d "$DIR" > /dev/null
    mv "$DIR/DIC-C2DH-HeLa/"* "$DIR" &> /dev/null # move dirs one level up
    rm -r "$DIR/DIC-C2DH-HeLa"
}

OPTS=$(getopt -o '' --long train:,test:,fetch,help -n 'setup' -- "$@")
if [ $? -ne 0 ]; then
    echo "Internal error! Failure to get optional arguments." >&2
    exit 1
fi

eval set -- "$OPTS"

TRAIN_DIR="DIC-C2DH-HeLa-Train"
TEST_DIR="DIC-C2DH-HeLa"
DOWNLOAD=false
HELP=false

while true; do
    case "$1" in
        --train)
            TRAIN_DIR="$2"
            shift 2
            ;;
        --test)
            TEST_DIR="$2"
            shift 2
            ;;
        --fetch) 
            DOWNLOAD=true
            shift
            ;;
        --help) 
            HELP=true
            shift
            ;;
        --)
            shift
            break
            ;;
        *)
            echo "Internal error! Failed to parse options." >&2
            exit 1
            ;;
    esac
done

if [ "$HELP" = true ]; then
    echo "setup [--train path] [--test path] [--help]:"
    echo "  --train        Path to the training dataset directory with CTC folder structure"
    echo "  --test         Path to the test dataset directory with CTC folder structure"
    echo "  --fetch        Download the DIC-C2Dh-HeLa dataset from the CTC site"
    exit 0
fi

cd ..

mkdir -p "$TRAIN_DIR/01_RES" "$TRAIN_DIR/02_RES" "$TEST_DIR/01_RES" "$TEST_DIR/02_RES"
# Download train and test datasets if running locally
if [ "$DOWNLOAD" = true ]; then
    # Download train, manually upload if on remote
    TRAIN_URL="http://data.celltrackingchallenge.net/training-datasets/DIC-C2DH-HeLa.zip"
    fetch_data "$TRAIN_URL" "$TRAIN_DIR"
    # Download test
    TEST_URL="http://data.celltrackingchallenge.net/test-datasets/DIC-C2DH-HeLa.zip"
    fetch_data "$TEST_URL" "$TEST_DIR"
fi

# Setup conda env
ENV="hela"
CONDA_DIR="$(conda info --base)"
source "$CONDA_DIR"/etc/profile.d/conda.sh
if [ ! -d "$CONDA_DIR/envs/$ENV" ] ; then # check if it exists
    conda env create --file=environment.yml -n "$ENV"
fi
conda activate "$ENV"

# Create Tensorflow dataset
TF_DIR=TFData
mkdir -p $TF_DIR/TFCache $TF_DIR/models
cd bin
# Re-running tfds for the same dataset will trigger an error
# and I'm just too lazy to write actual error handling
if [[ ! -d "../$TF_DIR/hela_test" && -d "../$TF_DIR/hela_train" ]]; then 
    python -m create_tfrecord --test "$TEST_DIR" --tf "$TF_DIR" # create for test
elif [[ -d "../$TF_DIR/hela_test" && ! -d "../$TF_DIR/hela_train" ]]; then 
    python -m create_tfrecord --train "$TRAIN_DIR" --tf "$TF_DIR" # create for train
elif [[ ! -d "../$TF_DIR/hela_test" && ! -d "../$TF_DIR/hela_train" ]]; then 
    python -m create_tfrecord --train "$TRAIN_DIR" --test "$TEST_DIR" --tf "$TF_DIR" # create for both
else
    : # do nothing
fi

exit 0
